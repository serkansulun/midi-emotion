python train.py --debug --log_step 100 --n_layer 8 --max_step 300 --no_amp

8 layers

CLUSTER - RTX 6000
SRUN is the same with SBATCH
AMP
ms/batch  483 | ms/sample  121, max_cached: 7698, nvsmi: 8548
NO AMP
ms/batch  715 | ms/sample  179, max_cached: 6964, nvsmi: 7814

PASCAL
AMP
ms/batch 1136 | ms/sample  284, max_cached: 9334, nvsmi: 10301
NO AMP
ms/batch 1115 | ms/sample  279, max_cached: 9498, nvsmi: 10465


